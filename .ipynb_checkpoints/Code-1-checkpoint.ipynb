{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f98d00f-64e4-4b52-8b44-cb974132f64a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AI-based Prediction Model for Blood-brain Barrier Penetrating Peptides\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The idea for this project comes from one of my previous lab works. BBB-penetrating peptides are a specific type of peptide that can conjugate with drugs to penetrate the blood-brain barrier and achieve therapeutic effects.\n",
    "I previously worked with DEA, a lead BBB-penetrating peptide. Previous studies have found a significant accumulation of DEA in rats' central nervous systems. However, the mechanism of penetration is not yet understood.\n",
    "\n",
    "\n",
    "![11.png](Images/11.png)\n",
    "\n",
    "\n",
    "Thus, we synthesized new peptides with several substitutions in the DEA sequence. Then, get some SAR information from in vitro BBB Translocation Assay. However, In vivo or in vitro validation of BBB-penetrating peptide is resource-intensive and time-consuming, so if we want to gain a deeper understanding of the DEA and do further optimization, itâ€™s better to have an accurate prediction method. So, the objective of my project is to **build an AI-based model to predict peptide penetration based on the sequence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157b28d-5186-4756-a1e3-06cffc00a684",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Machine Learning-based Prediction \n",
    "\n",
    "![22.png](Images/22.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813873ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "! pip install matplotlib-venn\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3de4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUMPY_DIR = './npy_res'\n",
    "CSV_DIR = './csv_res'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033539cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_pths = glob.glob(os.path.join(CSV_DIR, '*.csv'))\n",
    "csv_pths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232598b-c7da-456b-9114-7a6bd67b4c27",
   "metadata": {},
   "source": [
    "**Data Collection:**\n",
    "\n",
    "For data collection, I divided the data into three datasets for training. Positive data for all three datasets came from the B3Pdb database, totaling 269 BBB- penetrating peptides. Negative data for dataset 1 consisted of cell-penetrating peptides that cannot cross the BBB. For datasets 2 and 3, negative data were randomly selected from the non-BBB penetrating peptides database, dataset 3 having ten times entries than dataset 2.\n",
    "\n",
    "![33.png](Images/33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5a7b2",
   "metadata": {},
   "source": [
    "## (1) Feature Extraction\n",
    "\n",
    "Next, 15 types of peptide features were generated from the Composition-based Module in Pfeature, totaling 9189 features.\n",
    "\n",
    "![44.png](Images/44.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99603aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for csv_pth in csv_pths:\n",
    "    dataset = genfromtxt(csv_pth, delimiter=',', dtype=None)\n",
    "    \n",
    "    dataset = dataset[1:, :]\n",
    "    \n",
    "    dataset = dataset.astype('float64')\n",
    "\n",
    "    csv_base_name_split = os.path.basename(csv_pth[:-4]).split('_')\n",
    "    \n",
    "  \n",
    "    if not os.path.exists(NUMPY_DIR):\n",
    "        os.makedirs(NUMPY_DIR)      \n",
    "    npy_name = 'my_dataset_{}_{}_{}.npy'.format(csv_base_name_split[1], csv_base_name_split[2], csv_base_name_split[-1])\n",
    "    npy_name = os.path.join(NUMPY_DIR, npy_name)\n",
    "    \n",
    "    print('save data to {}'.format(npy_name), dataset.shape)\n",
    "    np.save(npy_name, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836b383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_3s = glob.glob('./npy_res/my_dataset_3_Training_N-*')\n",
    "datas = []\n",
    "for dataset_3 in dataset_3s:\n",
    "    datas += [np.load(dataset_3)]\n",
    "    \n",
    "datas = np.concatenate(datas)\n",
    "print('merge dataset3 to shape: ', datas.shape)\n",
    "np.save(os.path.join(NUMPY_DIR, 'my_dataset_3_Training_N.npy'), datas)\n",
    "\n",
    "\n",
    "for dataset_3 in dataset_3s:\n",
    "    if '-' in dataset_3:\n",
    "        print('remove {}'.format(dataset_3))\n",
    "        os.remove(dataset_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23d173",
   "metadata": {},
   "source": [
    "## (2) Feature Selection\n",
    "\n",
    "\n",
    "From these 9189 features, those with higher importance were selected using SVC-L1 for model training. The final selection for the three datasets was 56, 50, and 117 features, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48404c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names_result = list(pd.read_csv(csv_pths[0]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48086fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_importance(data_p_pth, data_n_pth, data_idx):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_p_pth : string. The path of the positive data\n",
    "    data_n_pth : string. The path of the negative data\n",
    "    data_idx   : int. The index of the dataset, which is used in the title of the figure.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_new : numpy array. The new feautres.\n",
    "    names : list of selected important features of their names.\n",
    "    importance : list of selected features with their importance.\n",
    "    selector : the model for selecting features\n",
    "    '''\n",
    "    x_1_p = np.load(data_p_pth, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "    y_1_p = np.ones((x_1_p.shape[0]))\n",
    "    \n",
    "    x_1_n = np.load(data_n_pth, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "    y_1_n = np.zeros((x_1_n.shape[0]))\n",
    "    \n",
    "    X = np.concatenate((x_1_p, x_1_n))\n",
    "    Y = np.concatenate((y_1_p, y_1_n))\n",
    "    X, Y = shuffle(X, Y)\n",
    "    \n",
    "    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "    selector = SelectFromModel(lsvc).fit(X, Y)\n",
    "    X_new = selector.transform(X)\n",
    "    \n",
    "    names = np.array(feature_names_result)[selector.get_support()].tolist()\n",
    "    importance =selector.estimator_.coef_[0][selector.get_support()].tolist()\n",
    "    importance_abs,names, importance = zip(*sorted(zip(abs(np.array(importance)),names, importance)))\n",
    "    title = 'Feature selection from dataset {}: {} to {}'.format(data_idx, X.shape[1], X_new.shape[1])\n",
    "    \n",
    "    H = 17\n",
    "    if len(importance) > 100:\n",
    "        H = 25\n",
    "    plt.figure(figsize=(10,H))\n",
    "    plt.title(title)\n",
    "    plt.barh(range(len(names)), abs(np.array(importance)), align='center', color='skyblue', label = 'absolute value of importance value')#, alpha=0.5)\n",
    "    plt.barh(range(len(names)), importance, align='center', label = 'orginal value')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return X_new, Y, names, importance, selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b854e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feautre selection from dataset 1\n",
    "X_new1, Y1, f1, inp1, selec1 = calculate_importance('./npy_res/my_dataset_1_Training_P.npy', './npy_res/my_dataset_1_Training_N.npy', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69c6d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feautre selection from dataset 2\n",
    "X_new2, Y2,f2, inp2, selec2 = calculate_importance('./npy_res/my_dataset_2_Training_P.npy', './npy_res/my_dataset_2_Training_N.npy', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3681c23",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feautre selection from dataset 3\n",
    "X_new3, Y3,f3, inp3, selec3 = calculate_importance('./npy_res/my_dataset_3_Training_P.npy', './npy_res/my_dataset_3_Training_N.npy', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caddcb1e",
   "metadata": {},
   "source": [
    "## (3) Analyze the number of selected features from 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91858e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "venn3(subsets=[set(f1), set(f2), set(f3)])\n",
    "print('overlapped important features from 3 datasets:')\n",
    "print(set(f1).intersection(set(f2)).intersection(set(f3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f7395",
   "metadata": {},
   "source": [
    "## (4) Classifier Comparison Method \n",
    "\n",
    "These selected features and the corresponding data were then used for model training on 9 different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ad8e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_names = ['Linear SVM', 'KNN', 'Gaussian Process', 'Decision Tree', 'Random Forest', 'Neural Net',\\\n",
    "                   'AdaBoost', 'Naive Bayes', 'QDA']\n",
    "classifers = [SVC(kernel=\"linear\", C=0.025, probability=True), \\\n",
    "             KNeighborsClassifier(3), \\\n",
    "             GaussianProcessClassifier(1.0 * RBF(1.0), max_iter_predict=10), \\\n",
    "             DecisionTreeClassifier(max_depth=5), \\\n",
    "             RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), \\\n",
    "             MLPClassifier(alpha=1, max_iter=1000), \\\n",
    "             AdaBoostClassifier(), \\\n",
    "             GaussianNB(), \\\n",
    "             QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c900a-d576-4bb7-92ac-46f20e945b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_curve, auc\n",
    "\n",
    "def train_models_and_evaluate(X, Y, selector, x_test_pths, classifiers, classifier_names):\n",
    "    X_train = X\n",
    "    Y_train = Y\n",
    "\n",
    "    X_valid_list = []\n",
    "    Y_valid_list = []\n",
    "    for x_test_pth in x_test_pths:\n",
    "        tmp_x_valid = np.load(x_test_pth, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "        X_valid_list.append(tmp_x_valid)\n",
    "        if 'P' in x_test_pth:\n",
    "            Y_valid_list.append(np.ones(tmp_x_valid.shape[0]))\n",
    "        else:\n",
    "            Y_valid_list.append(np.zeros(tmp_x_valid.shape[0]))\n",
    "\n",
    "    X_valid = np.concatenate(X_valid_list)\n",
    "    Y_valid = np.concatenate(Y_valid_list)\n",
    "    X_valid_transformed = selector.transform(X_valid)\n",
    "\n",
    "    metrics_dict = {'Classifier': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1': [], 'AUROC': []}\n",
    "\n",
    "    for clf_name, clf in zip(classifier_names, classifiers):\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred = clf.predict(X_valid_transformed)\n",
    "        pred_proba = clf.predict_proba(X_valid_transformed)[:, 1]\n",
    "\n",
    "        metrics_dict['Classifier'].append(clf_name)\n",
    "        metrics_dict['Accuracy'].append(metrics.accuracy_score(Y_valid, pred))\n",
    "        metrics_dict['Precision'].append(metrics.precision_score(Y_valid, pred))\n",
    "        metrics_dict['Recall'].append(metrics.recall_score(Y_valid, pred))\n",
    "        metrics_dict['F1'].append(metrics.f1_score(Y_valid, pred))\n",
    "        metrics_dict['AUROC'].append(metrics.roc_auc_score(Y_valid, pred_proba))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "    print(metrics_df)\n",
    "\n",
    "\n",
    "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1', 'AUROC']:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.bar(metrics_df['Classifier'], metrics_df[metric], color='blue')\n",
    "        plt.xlabel('Classifiers')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'{metric} of different classifiers')\n",
    "        plt.xticks(rotation=45)\n",
    "        # plt.savefig(f\"metrics_plot_{metric}.png\") \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=(len(classifiers) + 1) // 2, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    for ax, clf, name in zip(axes, classifiers, classifier_names):\n",
    "        plot_confusion_matrix(clf, X_valid_transformed, Y_valid, ax=ax, cmap='Blues')\n",
    "        ax.title.set_text(name)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"confusion_matrices.png\") \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for clf, name in zip(classifiers, classifier_names):\n",
    "        pred_proba = clf.predict_proba(X_valid_transformed)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(Y_valid, pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.savefig(\"roc_curves.png\") \n",
    "    plt.show()\n",
    "\n",
    "print('Results for dataset 1')\n",
    "print('=====================')\n",
    "train_models_and_evaluate(X_new1, Y1, selec1, ['./npy_res/my_dataset_1_Validation_P.npy', './npy_res/my_dataset_1_Validation_N.npy'], classifers, classifier_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1262a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Results for dataset 2')\n",
    "print('=====================')\n",
    "train_models_and_evaluate(X_new2, Y2, selec2, ['./npy_res/my_dataset_2_Validation_P.npy', './npy_res/my_dataset_2_Validation_N.npy'], classifers, classifier_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa34569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Results for dataset 3')\n",
    "print('=====================')\n",
    "train_models_and_evaluate(X_new3, Y3, selec3, ['./npy_res/my_dataset_3_Validation_P.npy', './npy_res/my_dataset_3_Validation_N.npy'], classifers, classifier_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d244aeb-b470-428b-8708-275b142fffa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summary:\n",
    "\n",
    "For dataset 1, Random Forest had the best accuracy at 0.76 and the highest precision score, F1 score, and ROC compared to other classifiers.\n",
    "\n",
    "For dataset 2, KNN and Random forest had the best accuracy at 0.79.\n",
    "\n",
    "For dataset 3, 9 classifiers can reach an accuracy of around 0.9. However, the confusion matrix shows that the model tends to predict a negative result. This is due to the imbalanced dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60415d-bfac-45da-8d65-21b86536a0e7",
   "metadata": {},
   "source": [
    "# 2. Sequential Model_LSTM\n",
    "\n",
    "Next, I tried using the deep learning method, the LSTM model, for training. LSTMs are particularly apt for peptide sequences because they can capture sequential information.\n",
    "\n",
    "![55.png](Images/55.png)\n",
    "\n",
    "## (1) Training data: Dataset 2\n",
    "\n",
    "First, I train the model using training dataset 2. The model reaches an accuracy of around 0.78, which is slightly better than Random Forest and KNN. The recall, F1, and AUROC scores are also higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef265e6-06b8-4e0e-b073-f023bf5900f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "file_list = glob.glob('/blue/bsc4892/Hsin-Ying/BBB Project/data_new/*.txt')  \n",
    "\n",
    "\n",
    "dataframes = [] \n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None)  \n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "sequences = combined_df[0].values  \n",
    "labels = combined_df[1].values.astype(int)  \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "encoded_seqs = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "\n",
    "X = pad_sequences(encoded_seqs, padding='post')\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde9821-a0c5-42fe-867c-ac653e1ab7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = 20 \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=50))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610871e-e6a3-4cbe-9775-c82fb685db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.savefig('model_accuracy_and_loss.png') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4384f-a393-4f27-92fd-501e1a7e899d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(x_test).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956c95c-55f1-4d18-a56b-dcd2c1079e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob('/blue/bsc4892/Hsin-Ying/BBB Project/data_DEA/*.txt')  \n",
    "\n",
    "\n",
    "dataframes = [] \n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None)  \n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "sequences = combined_df[0].values  \n",
    "labels = combined_df[1].values.astype(int)  \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "encoded_seqs = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "\n",
    "x_test_experiment = pad_sequences(encoded_seqs, padding='post')\n",
    "y_test_experiment = np.array(labels)\n",
    "\n",
    "\n",
    "y_pred_experiment = (model.predict(x_test_experiment) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_experiment, y_pred_experiment)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('confusion matrix.png') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(x_test_experiment).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test_experiment, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_experiment, y_pred_experiment)\n",
    "precision = precision_score(y_test_experiment, y_pred_experiment)\n",
    "recall = recall_score(y_test_experiment, y_pred_experiment)\n",
    "f1 = f1_score(y_test_experiment, y_pred_experiment)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a2923b-4b7e-4a15-8291-4d95218264ab",
   "metadata": {},
   "source": [
    "## (2) Training data: Dataset 3\n",
    "\n",
    "When using training dataset 3, similar to the previous result, with high accuracy but tends to predict the negative result, showing LSTM cannot deal with imbalanced data as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4e804-b3e2-40b6-b0f3-811d553412ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_list = glob.glob('/blue/bsc4892/Hsin-Ying/BBB Project/data_del/*.txt')  \n",
    "\n",
    "\n",
    "dataframes = [] \n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None)  \n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "sequences = combined_df[0].values  \n",
    "labels = combined_df[1].values.astype(int)  \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "encoded_seqs = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "\n",
    "X = pad_sequences(encoded_seqs, padding='post')\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acfda5-bb47-4dc3-80a0-c608e30cf4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 20 \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=50))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c680bf9-a013-4f74-8072-afd945c12e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad308d0d-145b-40d9-a368-776142e5d878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.savefig('model_accuracy_and_loss.png') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(x_test).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee07479-37b9-44bf-a41b-93dda3e395c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob('/blue/bsc4892/Hsin-Ying/BBB Project/data_DEA/*.txt')  \n",
    "\n",
    "\n",
    "dataframes = [] \n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None)  \n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "sequences = combined_df[0].values  \n",
    "labels = combined_df[1].values.astype(int)  \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "encoded_seqs = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "\n",
    "x_test_experiment = pad_sequences(encoded_seqs, padding='post')\n",
    "y_test_experiment = np.array(labels)\n",
    "\n",
    "\n",
    "y_pred_experiment = (model.predict(x_test_experiment) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_experiment, y_pred_experiment)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "# plt.savefig('confusion matrix.png') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(x_test_experiment).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test_experiment, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_experiment, y_pred_experiment)\n",
    "precision = precision_score(y_test_experiment, y_pred_experiment)\n",
    "recall = recall_score(y_test_experiment, y_pred_experiment)\n",
    "f1 = f1_score(y_test_experiment, y_pred_experiment)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5066e37-f116-4d59-ad02-73bd90966891",
   "metadata": {},
   "source": [
    "Although LSTM shows a similar or slightly better performance than previous classifiers, when testing on the assay data, the accuracy is pretty low for both training dataset. So, the next method is to add augmented data for both positive and negative data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528bc156-9734-4283-b526-68edf96ba9a7",
   "metadata": {},
   "source": [
    "## (3) Training data: Augumented data\n",
    "\n",
    "The method for data augmentation is random masking. The new data set has around 7,500 entries. The overall performance with the augmented data is improved. It also could better predict both true positive and negative data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf11f01-f401-4efb-92ea-a763db99b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_list = glob.glob('/blue/bsc4892/Hsin-Ying/BBB Project/final_combined_data.txt')  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataframes = [] \n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None)  \n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "sequences = combined_df[0].values  \n",
    "labels = combined_df[1].values.astype(int)  \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "encoded_seqs = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "\n",
    "X = pad_sequences(encoded_seqs, padding='post')\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "vocab_size = 20 \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=50))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=35, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fd2dd-cec4-4759-9dc4-14c8bae86939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('model_accuracy_and_loss.png') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('1') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(x_test).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('2') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20e603-3804-4160-b2db-d26c58850b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob('/blue/bsc4892/Hsin-Ying/BBB Project/data_DEA/*.txt')  \n",
    "\n",
    "\n",
    "dataframes = [] \n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None)  \n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "sequences = combined_df[0].values  \n",
    "labels = combined_df[1].values.astype(int)  \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "encoded_seqs = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "\n",
    "x_test_experiment = pad_sequences(encoded_seqs, padding='post')\n",
    "y_test_experiment = np.array(labels)\n",
    "\n",
    "\n",
    "y_pred_experiment = (model.predict(x_test_experiment) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_experiment, y_pred_experiment)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('confusion matrix.png') \n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(x_test_experiment).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test_experiment, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test_experiment, y_pred_experiment)\n",
    "precision = precision_score(y_test_experiment, y_pred_experiment)\n",
    "recall = recall_score(y_test_experiment, y_pred_experiment)\n",
    "f1 = f1_score(y_test_experiment, y_pred_experiment)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413c20a-7af0-4a80-b59d-00cceca98e85",
   "metadata": {},
   "source": [
    "When testing on the assay data, the accuracy also significantly improved to 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4580f6-a765-4ce0-9a7c-ee4cb0449f2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Comparision of Prediction on Assay Data**\n",
    "\n",
    "![66.png](Images/66.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e29ee4-8847-4173-a779-8205fe6318a2",
   "metadata": {},
   "source": [
    "# 2. Conclusion\n",
    "(1) **For Machine Learning-based Prediction**, using a random forest with selected features could reach an accuracy of 0.79. Sequence features could provide more information for optimization and SAR analysis.\n",
    "\n",
    "(2) **For the Deep Learning-based method**, the performance of the LSTM model is sensitive to the quantity and quality of the training data. 8x augmented data could reach an accuracy of 0.98. \n",
    "\n",
    "(3) **Limitations of this project**:\n",
    "The assay dataset for testing is small and contains only a single mutation for each peptide. The BBB-penetrating peptides database also has limited data. So, the model cannot identify the slight difference between single mutation data, so the accuracy of classifying assay data is relatively low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
